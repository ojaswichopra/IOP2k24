{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a94a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "import visualkeras\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Conv2D, Flatten, GlobalAveragePooling2D, BatchNormalization, Activation, MaxPooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "SEED = 15\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0870c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b074e06c1d946e0903826128fce3e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images:   0%|          | 0/1499 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c214a7b30114ee89228b126de1dc95e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "images:   0%|          | 0/1500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_images_list(path):\n",
    "    full_path = []\n",
    "    images = os.listdir(path)\n",
    "    for i in tqdm(images, desc = 'images' ):\n",
    "        full_path.append(os.path.join(path, i))\n",
    "        \n",
    "    return full_path\n",
    "\n",
    "\n",
    "data_healthy = create_images_list(\"../Datasetdown-syndrome-classification\\healty\\healty\")\n",
    "data_down = create_images_list(\"../Datasetdown-syndrome-classification\\downSyndorme\\downSyndrome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff9503b",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_classes = {0:'healthy', 1 : 'down' }\n",
    "\n",
    "data_df = pd.concat([  pd.DataFrame({\"img\" : np.array(data_healthy) , \"label\": 0 }),\n",
    "                        pd.DataFrame({\"img\" : np.array(data_down) , \"label\": 1 }) ], ignore_index = True)\n",
    "\n",
    "\n",
    "data_df = shuffle(data_df).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33f4e783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train images:  2549\n",
      "test images:  450\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data_df['img'], data_df['label'], test_size = 0.15,  random_state = SEED)\n",
    "\n",
    "print(\"train images: \", X_train.shape[0])\n",
    "print(\"test images: \", X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2eee34eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocessing(image, label):\n",
    "    \n",
    "    img = tf.io.read_file(image)\n",
    "    img = tf.io.decode_jpeg(img, channels = 3)\n",
    "    img = tf.image.resize(img, size = (250,250))\n",
    "    img = img/255.0\n",
    "    \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fc8bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = tf.data.Dataset.from_tensor_slices(( X_train, y_train) )\n",
    "train_dataset = (train_loader.map(img_preprocessing).batch(BATCH_SIZE).shuffle(X_train.shape[0]).prefetch(BATCH_SIZE))\n",
    "\n",
    "test_loader = tf.data.Dataset.from_tensor_slices(( X_test, y_test) )\n",
    "test_dataset = (test_loader.map(img_preprocessing).batch(BATCH_SIZE).prefetch(BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8219ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prash\\anaconda3\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\prash\\anaconda3\\lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 250, 250, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 250, 250, 32)      416       \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 250, 250, 32)      128       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 250, 250, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 125, 125, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      8256      \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 125, 125, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 125, 125, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 62, 62, 128)       32896     \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 62, 62, 128)       512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 62, 62, 128)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 31, 31, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 31, 31, 256)       131328    \n",
      "                                                                 \n",
      " batch_normalization_3 (Bat  (None, 31, 31, 256)       1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 31, 31, 256)       0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 15, 15, 256)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " global_average_pooling2d (  (None, 256)               0         \n",
      " GlobalAveragePooling2D)                                         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                16448     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                4160      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 195489 (763.63 KB)\n",
      "Trainable params: 194529 (759.88 KB)\n",
      "Non-trainable params: 960 (3.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "In = Input(shape=(250, 250, 3))\n",
    "\n",
    "conv2 = Conv2D(32, 2, padding = 'same')(In)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('elu')(conv2)\n",
    "conv2 = MaxPooling2D(2)(conv2)\n",
    "\n",
    "conv2 = Conv2D(64, 2, padding = 'same')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('elu')(conv2)\n",
    "conv2 = MaxPooling2D(2)(conv2)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(128, 2, padding = 'same')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('elu')(conv2)\n",
    "conv2 = MaxPooling2D(2)(conv2)\n",
    "\n",
    "\n",
    "conv2 = Conv2D(256, 2, padding = 'same')(conv2)\n",
    "conv2 = BatchNormalization()(conv2)\n",
    "conv2 = Activation('elu')(conv2)\n",
    "conv2 = MaxPooling2D(2)(conv2)\n",
    "\n",
    "pool = GlobalAveragePooling2D()(conv2)\n",
    "drop = Dropout(0.6)(pool)\n",
    "dense1 = Dense(64, activation = 'relu')(drop)\n",
    "dense1 = Dense(64, activation = 'relu')(dense1)\n",
    "Out = Dense(1, activation = 'sigmoid')(dense1)\n",
    "\n",
    "model = Model(inputs = In, outputs = Out)\n",
    "\n",
    "model.compile(optimizer  = tf.keras.optimizers.Adam(), loss = 'binary_crossentropy', metrics = ['accuracy','AUC','Precision','Recall'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebe66f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\prash\\anaconda3\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\prash\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "319/319 [==============================] - 80s 222ms/step - loss: 0.6387 - accuracy: 0.6348 - auc: 0.6896 - precision: 0.6331 - recall: 0.6484\n",
      "Epoch 2/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.6175 - accuracy: 0.6689 - auc: 0.7250 - precision: 0.6708 - recall: 0.6687\n",
      "Epoch 3/100\n",
      "319/319 [==============================] - 72s 223ms/step - loss: 0.5913 - accuracy: 0.6791 - auc: 0.7523 - precision: 0.6684 - recall: 0.7164\n",
      "Epoch 4/100\n",
      "319/319 [==============================] - 75s 232ms/step - loss: 0.5874 - accuracy: 0.6967 - auc: 0.7570 - precision: 0.6934 - recall: 0.7102\n",
      "Epoch 5/100\n",
      "319/319 [==============================] - 80s 245ms/step - loss: 0.5809 - accuracy: 0.6897 - auc: 0.7602 - precision: 0.6799 - recall: 0.7219\n",
      "Epoch 6/100\n",
      "319/319 [==============================] - 84s 259ms/step - loss: 0.5779 - accuracy: 0.6924 - auc: 0.7623 - precision: 0.6771 - recall: 0.7406\n",
      "Epoch 7/100\n",
      "319/319 [==============================] - 83s 254ms/step - loss: 0.5643 - accuracy: 0.7050 - auc: 0.7784 - precision: 0.6950 - recall: 0.7352\n",
      "Epoch 8/100\n",
      "319/319 [==============================] - 89s 273ms/step - loss: 0.5654 - accuracy: 0.7034 - auc: 0.7784 - precision: 0.6918 - recall: 0.7383\n",
      "Epoch 9/100\n",
      "319/319 [==============================] - 83s 256ms/step - loss: 0.5640 - accuracy: 0.7038 - auc: 0.7807 - precision: 0.6966 - recall: 0.7266\n",
      "Epoch 10/100\n",
      "319/319 [==============================] - 76s 235ms/step - loss: 0.5617 - accuracy: 0.7054 - auc: 0.7809 - precision: 0.6935 - recall: 0.7406\n",
      "Epoch 11/100\n",
      "319/319 [==============================] - 75s 232ms/step - loss: 0.5562 - accuracy: 0.7022 - auc: 0.7836 - precision: 0.6906 - recall: 0.7375\n",
      "Epoch 12/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.5477 - accuracy: 0.7191 - auc: 0.7943 - precision: 0.7153 - recall: 0.7320\n",
      "Epoch 13/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.5477 - accuracy: 0.7199 - auc: 0.7940 - precision: 0.7016 - recall: 0.7695\n",
      "Epoch 14/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.5471 - accuracy: 0.7171 - auc: 0.7967 - precision: 0.7094 - recall: 0.7398\n",
      "Epoch 15/100\n",
      "319/319 [==============================] - 78s 241ms/step - loss: 0.5446 - accuracy: 0.7215 - auc: 0.7980 - precision: 0.7143 - recall: 0.7422\n",
      "Epoch 16/100\n",
      "319/319 [==============================] - 76s 235ms/step - loss: 0.5451 - accuracy: 0.7222 - auc: 0.7980 - precision: 0.7072 - recall: 0.7625\n",
      "Epoch 17/100\n",
      "319/319 [==============================] - 76s 232ms/step - loss: 0.5419 - accuracy: 0.7281 - auc: 0.8001 - precision: 0.7166 - recall: 0.7586\n",
      "Epoch 18/100\n",
      "319/319 [==============================] - 75s 229ms/step - loss: 0.5338 - accuracy: 0.7230 - auc: 0.8070 - precision: 0.7095 - recall: 0.7594\n",
      "Epoch 19/100\n",
      "319/319 [==============================] - 77s 237ms/step - loss: 0.5305 - accuracy: 0.7277 - auc: 0.8092 - precision: 0.7111 - recall: 0.7711\n",
      "Epoch 20/100\n",
      "319/319 [==============================] - 76s 232ms/step - loss: 0.5272 - accuracy: 0.7305 - auc: 0.8129 - precision: 0.7218 - recall: 0.7539\n",
      "Epoch 21/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.5261 - accuracy: 0.7321 - auc: 0.8158 - precision: 0.7219 - recall: 0.7586\n",
      "Epoch 22/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.5165 - accuracy: 0.7395 - auc: 0.8225 - precision: 0.7391 - recall: 0.7437\n",
      "Epoch 23/100\n",
      "319/319 [==============================] - 75s 232ms/step - loss: 0.5157 - accuracy: 0.7489 - auc: 0.8236 - precision: 0.7439 - recall: 0.7625\n",
      "Epoch 24/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.5138 - accuracy: 0.7415 - auc: 0.8255 - precision: 0.7409 - recall: 0.7461\n",
      "Epoch 25/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.5214 - accuracy: 0.7340 - auc: 0.8205 - precision: 0.7308 - recall: 0.7445\n",
      "Epoch 26/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.5197 - accuracy: 0.7391 - auc: 0.8191 - precision: 0.7404 - recall: 0.7398\n",
      "Epoch 27/100\n",
      "319/319 [==============================] - 76s 234ms/step - loss: 0.5065 - accuracy: 0.7462 - auc: 0.8297 - precision: 0.7367 - recall: 0.7695\n",
      "Epoch 28/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.5004 - accuracy: 0.7564 - auc: 0.8361 - precision: 0.7544 - recall: 0.7633\n",
      "Epoch 29/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.5105 - accuracy: 0.7477 - auc: 0.8283 - precision: 0.7323 - recall: 0.7844\n",
      "Epoch 30/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4959 - accuracy: 0.7591 - auc: 0.8376 - precision: 0.7485 - recall: 0.7836\n",
      "Epoch 31/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.5011 - accuracy: 0.7595 - auc: 0.8348 - precision: 0.7502 - recall: 0.7812\n",
      "Epoch 32/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.4980 - accuracy: 0.7548 - auc: 0.8367 - precision: 0.7421 - recall: 0.7844\n",
      "Epoch 33/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4915 - accuracy: 0.7591 - auc: 0.8401 - precision: 0.7515 - recall: 0.7773\n",
      "Epoch 34/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4887 - accuracy: 0.7630 - auc: 0.8432 - precision: 0.7564 - recall: 0.7789\n",
      "Epoch 35/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4788 - accuracy: 0.7693 - auc: 0.8513 - precision: 0.7571 - recall: 0.7961\n",
      "Epoch 36/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4901 - accuracy: 0.7678 - auc: 0.8434 - precision: 0.7663 - recall: 0.7734\n",
      "Epoch 37/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.4789 - accuracy: 0.7740 - auc: 0.8518 - precision: 0.7695 - recall: 0.7852\n",
      "Epoch 38/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4816 - accuracy: 0.7666 - auc: 0.8483 - precision: 0.7577 - recall: 0.7867\n",
      "Epoch 39/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4712 - accuracy: 0.7717 - auc: 0.8555 - precision: 0.7735 - recall: 0.7711\n",
      "Epoch 40/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.4642 - accuracy: 0.7713 - auc: 0.8589 - precision: 0.7675 - recall: 0.7812\n",
      "Epoch 41/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.4733 - accuracy: 0.7760 - auc: 0.8538 - precision: 0.7692 - recall: 0.7914\n",
      "Epoch 42/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.4626 - accuracy: 0.7807 - auc: 0.8605 - precision: 0.7708 - recall: 0.8016\n",
      "Epoch 43/100\n",
      "319/319 [==============================] - 76s 233ms/step - loss: 0.4599 - accuracy: 0.7850 - auc: 0.8636 - precision: 0.7785 - recall: 0.7992\n",
      "Epoch 44/100\n",
      "319/319 [==============================] - 75s 232ms/step - loss: 0.4641 - accuracy: 0.7807 - auc: 0.8620 - precision: 0.7779 - recall: 0.7883\n",
      "Epoch 45/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.4593 - accuracy: 0.7850 - auc: 0.8643 - precision: 0.7785 - recall: 0.7992\n",
      "Epoch 46/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.4544 - accuracy: 0.7846 - auc: 0.8680 - precision: 0.7758 - recall: 0.8031\n",
      "Epoch 47/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.4500 - accuracy: 0.7823 - auc: 0.8689 - precision: 0.7732 - recall: 0.8016\n",
      "Epoch 48/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4518 - accuracy: 0.7889 - auc: 0.8693 - precision: 0.7828 - recall: 0.8023\n",
      "Epoch 49/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4454 - accuracy: 0.7980 - auc: 0.8732 - precision: 0.7891 - recall: 0.8156\n",
      "Epoch 50/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.4473 - accuracy: 0.7909 - auc: 0.8720 - precision: 0.7893 - recall: 0.7961\n",
      "Epoch 51/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.4507 - accuracy: 0.7870 - auc: 0.8693 - precision: 0.7868 - recall: 0.7898\n",
      "Epoch 52/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.4450 - accuracy: 0.7995 - auc: 0.8739 - precision: 0.8035 - recall: 0.7953\n",
      "Epoch 53/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4320 - accuracy: 0.8023 - auc: 0.8806 - precision: 0.7989 - recall: 0.8102\n",
      "Epoch 54/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4352 - accuracy: 0.8038 - auc: 0.8791 - precision: 0.8000 - recall: 0.8125\n",
      "Epoch 55/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4384 - accuracy: 0.7948 - auc: 0.8768 - precision: 0.7978 - recall: 0.7922\n",
      "Epoch 56/100\n",
      "319/319 [==============================] - 81s 250ms/step - loss: 0.4244 - accuracy: 0.8031 - auc: 0.8837 - precision: 0.7983 - recall: 0.8133\n",
      "Epoch 57/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4285 - accuracy: 0.8035 - auc: 0.8840 - precision: 0.8069 - recall: 0.8000\n",
      "Epoch 58/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.4273 - accuracy: 0.8117 - auc: 0.8843 - precision: 0.8101 - recall: 0.8164\n",
      "Epoch 59/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4130 - accuracy: 0.8148 - auc: 0.8918 - precision: 0.8137 - recall: 0.8188\n",
      "Epoch 60/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4189 - accuracy: 0.8062 - auc: 0.8876 - precision: 0.8075 - recall: 0.8062\n",
      "Epoch 61/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4052 - accuracy: 0.8027 - auc: 0.8962 - precision: 0.8052 - recall: 0.8008\n",
      "Epoch 62/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.4181 - accuracy: 0.8082 - auc: 0.8898 - precision: 0.8087 - recall: 0.8094\n",
      "Epoch 63/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.4089 - accuracy: 0.8078 - auc: 0.8945 - precision: 0.8105 - recall: 0.8055\n",
      "Epoch 64/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.4023 - accuracy: 0.8144 - auc: 0.8979 - precision: 0.8150 - recall: 0.8156\n",
      "Epoch 65/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4086 - accuracy: 0.8144 - auc: 0.8935 - precision: 0.8101 - recall: 0.8234\n",
      "Epoch 66/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.4002 - accuracy: 0.8176 - auc: 0.8980 - precision: 0.8147 - recall: 0.8242\n",
      "Epoch 67/100\n",
      "319/319 [==============================] - 76s 233ms/step - loss: 0.3982 - accuracy: 0.8172 - auc: 0.9000 - precision: 0.8195 - recall: 0.8156\n",
      "Epoch 68/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.3909 - accuracy: 0.8191 - auc: 0.9032 - precision: 0.8268 - recall: 0.8094\n",
      "Epoch 69/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3938 - accuracy: 0.8290 - auc: 0.9031 - precision: 0.8318 - recall: 0.8266\n",
      "Epoch 70/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3888 - accuracy: 0.8258 - auc: 0.9042 - precision: 0.8255 - recall: 0.8281\n",
      "Epoch 71/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3885 - accuracy: 0.8235 - auc: 0.9057 - precision: 0.8268 - recall: 0.8203\n",
      "Epoch 72/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.3883 - accuracy: 0.8227 - auc: 0.9048 - precision: 0.8291 - recall: 0.8148\n",
      "Epoch 73/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.3822 - accuracy: 0.8246 - auc: 0.9088 - precision: 0.8192 - recall: 0.8352\n",
      "Epoch 74/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3893 - accuracy: 0.8270 - auc: 0.9046 - precision: 0.8219 - recall: 0.8367\n",
      "Epoch 75/100\n",
      "319/319 [==============================] - 75s 231ms/step - loss: 0.3790 - accuracy: 0.8270 - auc: 0.9101 - precision: 0.8295 - recall: 0.8250\n",
      "Epoch 76/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3729 - accuracy: 0.8333 - auc: 0.9129 - precision: 0.8281 - recall: 0.8430\n",
      "Epoch 77/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3802 - accuracy: 0.8301 - auc: 0.9091 - precision: 0.8306 - recall: 0.8313\n",
      "Epoch 78/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3705 - accuracy: 0.8290 - auc: 0.9139 - precision: 0.8328 - recall: 0.8250\n",
      "Epoch 79/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.3717 - accuracy: 0.8352 - auc: 0.9141 - precision: 0.8397 - recall: 0.8305\n",
      "Epoch 80/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3690 - accuracy: 0.8266 - auc: 0.9142 - precision: 0.8218 - recall: 0.8359\n",
      "Epoch 81/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3739 - accuracy: 0.8286 - auc: 0.9119 - precision: 0.8265 - recall: 0.8336\n",
      "Epoch 82/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3623 - accuracy: 0.8392 - auc: 0.9182 - precision: 0.8336 - recall: 0.8492\n",
      "Epoch 83/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3589 - accuracy: 0.8333 - auc: 0.9195 - precision: 0.8396 - recall: 0.8258\n",
      "Epoch 84/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3582 - accuracy: 0.8392 - auc: 0.9195 - precision: 0.8362 - recall: 0.8453\n",
      "Epoch 85/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3623 - accuracy: 0.8423 - auc: 0.9185 - precision: 0.8398 - recall: 0.8477\n",
      "Epoch 86/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3511 - accuracy: 0.8388 - auc: 0.9228 - precision: 0.8309 - recall: 0.8523\n",
      "Epoch 87/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.3591 - accuracy: 0.8372 - auc: 0.9199 - precision: 0.8376 - recall: 0.8383\n",
      "Epoch 88/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3673 - accuracy: 0.8301 - auc: 0.9154 - precision: 0.8225 - recall: 0.8438\n",
      "Epoch 89/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3571 - accuracy: 0.8352 - auc: 0.9192 - precision: 0.8248 - recall: 0.8531\n",
      "Epoch 90/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3455 - accuracy: 0.8470 - auc: 0.9256 - precision: 0.8439 - recall: 0.8531\n",
      "Epoch 91/100\n",
      "319/319 [==============================] - 74s 229ms/step - loss: 0.3548 - accuracy: 0.8352 - auc: 0.9208 - precision: 0.8248 - recall: 0.8531\n",
      "Epoch 92/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3449 - accuracy: 0.8486 - auc: 0.9252 - precision: 0.8460 - recall: 0.8539\n",
      "Epoch 93/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.3409 - accuracy: 0.8403 - auc: 0.9272 - precision: 0.8495 - recall: 0.8289\n",
      "Epoch 94/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3401 - accuracy: 0.8466 - auc: 0.9276 - precision: 0.8422 - recall: 0.8547\n",
      "Epoch 95/100\n",
      "319/319 [==============================] - 75s 230ms/step - loss: 0.3468 - accuracy: 0.8423 - auc: 0.9254 - precision: 0.8408 - recall: 0.8461\n",
      "Epoch 96/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3258 - accuracy: 0.8548 - auc: 0.9339 - precision: 0.8495 - recall: 0.8641\n",
      "Epoch 97/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3292 - accuracy: 0.8478 - auc: 0.9327 - precision: 0.8447 - recall: 0.8539\n",
      "Epoch 98/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3284 - accuracy: 0.8580 - auc: 0.9326 - precision: 0.8536 - recall: 0.8656\n",
      "Epoch 99/100\n",
      "319/319 [==============================] - 74s 227ms/step - loss: 0.3266 - accuracy: 0.8627 - auc: 0.9342 - precision: 0.8633 - recall: 0.8633\n",
      "Epoch 100/100\n",
      "319/319 [==============================] - 74s 228ms/step - loss: 0.3304 - accuracy: 0.8588 - auc: 0.9325 - precision: 0.8549 - recall: 0.8656\n"
     ]
    }
   ],
   "source": [
    "my_callbacks = [EarlyStopping(monitor = 'loss', patience = 8, min_delta = 0.0001)]\n",
    "\n",
    "hist = model.fit(train_dataset, epochs = 100, verbose =1, callbacks = my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba6e0ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 6s 82ms/step - loss: 0.5242 - accuracy: 0.7844 - auc: 0.8616 - precision: 0.7375 - recall: 0.8682\n"
     ]
    }
   ],
   "source": [
    "test_eval = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c27f6a27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 3s 52ms/step\n"
     ]
    }
   ],
   "source": [
    "test_take1 =  test_dataset.take(-1)\n",
    "test_take1_ = list(test_take1)\n",
    "pred = model.predict(test_take1)\n",
    "pred_ = np.round(pred)\n",
    "\n",
    "y_test_take = []\n",
    "for x in range(len(test_take1_)):\n",
    "    y_test_take.extend(test_take1_[x][1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f54afa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[162,  68],\n",
       "       [ 29, 191]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_take, pred_)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2026828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.70      0.77       230\n",
      "           1       0.74      0.87      0.80       220\n",
      "\n",
      "    accuracy                           0.78       450\n",
      "   macro avg       0.79      0.79      0.78       450\n",
      "weighted avg       0.79      0.78      0.78       450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cr = classification_report(np.array(y_test_take), pred_)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73d9b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
